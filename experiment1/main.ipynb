{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each data point in `all_hand_labeled.json` has a prompt, ChatGPT response, and response tone attribute. In this experiment, we are interested in ChatGPT's response, and the response tone. In particular, labels are the response tones (multi-class), which are converted into integers. Notable libraries are PyTorch and Scikit-learn.\n",
    "\n",
    "This experiment uses unsupervised learning to learn how to represent a ChatGPT response (vectoried using TF-IDF) in a low-dimensional space, then reconstruct it (this is done with a variational autoencoder, or VAE). It also uses supervised learning, using the encoding of the variational autoencoder to predict whether a given ChatGPT response was a refusal. This part uses logistic regression and obtains 87.89% accuracy.\n",
    "\n",
    "We perturb the latent space of a response encoding to see how it affects the reconstruction. With a response of \"I'm sorry, I cannot comply with this request as it promotes violence and goes against the ethical guidelines of OpenAI.\", the perturbed reconstruction adds the words {'harm', 'my', 'or', 'violent', 'hate'}, and removes the words {'policy', 'condone'}.\n",
    "\n",
    "This experiment shows that we can indeed use a VAE to get a latent representation of ChatGPT responses (and therefore prompts) that can also be used for classification to a reasonable degree of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies.\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a fixed randomness for reproducibility.\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how to load and preprocess the data.\n",
    "\n",
    "def preprocess_data(file_path, text_source):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Filter out unwanted classes\n",
    "    df = df.loc[~df['tone'].isin(['incoherent', 'dontknow'])].copy()\n",
    "\n",
    "    # Change any label that isn't \"complied\" to \"rejected\"\n",
    "    df.loc[~df['tone'].isin(['complied', 'rejected']), 'tone'] = 'rejected'\n",
    "\n",
    "    X = df[text_source].tolist()\n",
    "    y = df['tone'].tolist()\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how to split the data into train/val/test.\n",
    "\n",
    "def split_data(X, y):\n",
    "    # This yields a 70/15/15 train/validation/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=0)\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess labeled refusals into train/val/test.\n",
    "\n",
    "X, y = preprocess_data('all_hand_labeled.json', 'response')\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the data using TF-IDF.\n",
    "\n",
    "# Yields a matrix where:\n",
    "    # Each row is a representation of a document (i.e. ChatGPT responses).\n",
    "    # Each column corresponds to one of the top 5000 words (or less) by term frequency across the corpus.\n",
    "        # Values in each column are the TF-IDF scores for that word in the document.\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train).toarray()\n",
    "X_test_tfidf = vectorizer.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variational autoencoder (VAE) model class.\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "        # Hyperparameters\n",
    "        self.hidden_dim = 500\n",
    "        self.latent_dim = 20\n",
    "        self.batch_size = 16\n",
    "        self.learning_rate = 1e-3\n",
    "\n",
    "        # Encoding layers (learn the mean and log variance of the latent space)\n",
    "        self.fc1 = nn.Linear(self.input_dim, self.hidden_dim)       # Input to hidden layer\n",
    "        self.fc21 = nn.Linear(self.hidden_dim, self.latent_dim)     # Hidden to latent mean\n",
    "        self.fc22 = nn.Linear(self.hidden_dim, self.latent_dim)     # Hidden to latent log variance\n",
    "\n",
    "        # Decoding layers (reconstruct the input from the latent space)\n",
    "        self.fc3 = nn.Linear(self.latent_dim, self.hidden_dim)      # Latent to hidden layer\n",
    "        self.fc4 = nn.Linear(self.hidden_dim, self.input_dim)       # Hidden to reconstructed input layer\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))    # fc1  layer's output after ReLU\n",
    "        means = self.fc21(h1)       # fc21 layer's output (means of latent space)\n",
    "        logvars = self.fc22(h1)     # fc22 layer's output (log variances of latent space)\n",
    "        return means, logvars\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))                        # fc3 layer's output after ReLU\n",
    "        reconstruction = torch.sigmoid(self.fc4(h3))    # fc4 layer's output after sigmoid (bounds to [0, 1])\n",
    "        return reconstruction\n",
    "\n",
    "    def sample_from_latent_distribution(self, means, logvars):\n",
    "        stds = torch.exp(0.5 * logvars)     # logvar is log(sigma^2), so std is sigma (0.5 is for square root)\n",
    "        epsilons = torch.randn_like(stds)   # Vector of random numbers from a standard normal distribution N(0, 1)\n",
    "        noises = stds * epsilons\n",
    "        sample = means + noises             # Shift the means according to the noises\n",
    "        return sample\n",
    "    \n",
    "    def get_latent_encoding(self, x):\n",
    "        means, _ = self.encode(torch.FloatTensor(x))\n",
    "        return means\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Get means and logvars\n",
    "        means, logvars = self.encode(\n",
    "            x.view(-1, self.input_dim) # Flatten original data to match decoder's output shape\n",
    "        ) \n",
    "        \n",
    "        sample = self.sample_from_latent_distribution(means, logvars)   # Sample from resulting latent distribution\n",
    "        return self.decode(sample), means, logvars                      # Return reconstruction, means, and logvars\n",
    "\n",
    "    def calculate_loss(self, reconstruction, original, means, logvars):\n",
    "        # Use binary cross entropy to measure the difference between the original data and the reconstruction.\n",
    "        binary_cross_entropy = F.binary_cross_entropy(\n",
    "            reconstruction, \n",
    "            original.view(-1, self.input_dim), # Flatten original data to match decoder's output shape\n",
    "            reduction='sum' # Summing loss over all elements of the batch is a common for VAE loss functions\n",
    "        )\n",
    "\n",
    "        # Use KL divergence to penalize divergences of the distribution ~(means, logvars) from the standard normal\n",
    "        # distribution.\n",
    "        KL_divergence = -0.5 * torch.sum(1 + logvars - means.pow(2) - logvars.exp())\n",
    "\n",
    "        loss =  (\n",
    "            binary_cross_entropy    # Reconstruction loss.\n",
    "          + KL_divergence           # Loss for deviating the latent space from a standard normal distribution.\n",
    "        )\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def custom_train(self, train_data, model_save_path, epochs):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate) # Updates weights + manages learning rate\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "            train_data,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True # Randomize ordering of feeding in datapoints for each epoch\n",
    "        )\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            train_loss = 0\n",
    "            for batch_idx, (data, _) in enumerate(train_loader):\n",
    "                optimizer.zero_grad()                                           # Reset gradients to 0\n",
    "                recon_batch, means, logvars = self(data)                        # Forward pass\n",
    "\n",
    "                # Calculate loss, combining reconstruction loss and standard normal distribution divergence loss\n",
    "                loss = self.calculate_loss(recon_batch, data, means, logvars)\n",
    "\n",
    "                loss.backward()                                                 # Backward pass\n",
    "                train_loss += loss.item()\n",
    "                optimizer.step()                                                # Update weights\n",
    "            print(f'Epoch {epoch}, Loss: {train_loss / len(train_loader.dataset)}')\n",
    "\n",
    "        torch.save(self.state_dict(), model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 516.4635168743293\n",
      "Epoch 1, Loss: 61.00613842937016\n",
      "Epoch 2, Loss: 57.77654257411733\n",
      "Epoch 3, Loss: 55.18874391079748\n",
      "Epoch 4, Loss: 54.17691474543944\n",
      "Epoch 5, Loss: 52.832628004115634\n",
      "Epoch 6, Loss: 51.933425136546994\n",
      "Epoch 7, Loss: 50.72123950849626\n",
      "Epoch 8, Loss: 49.84438394262164\n",
      "Epoch 9, Loss: 49.3446845944403\n",
      "Epoch 10, Loss: 49.044978718462104\n",
      "Epoch 11, Loss: 48.91553521595608\n",
      "Epoch 12, Loss: 48.41435742657788\n",
      "Epoch 13, Loss: 48.38075683184804\n",
      "Epoch 14, Loss: 48.070711988899575\n",
      "Epoch 15, Loss: 47.78410755968972\n",
      "Epoch 16, Loss: 47.59464748261163\n",
      "Epoch 17, Loss: 47.519513946482085\n",
      "Epoch 18, Loss: 47.18028831801423\n",
      "Epoch 19, Loss: 46.96460167966296\n",
      "Epoch 20, Loss: 46.573065190658696\n",
      "Epoch 21, Loss: 46.52131977432737\n",
      "Epoch 22, Loss: 46.23207641806035\n",
      "Epoch 23, Loss: 46.02705168604252\n",
      "Epoch 24, Loss: 45.798949760807616\n",
      "Epoch 25, Loss: 45.50038727164468\n",
      "Epoch 26, Loss: 45.516551671116\n",
      "Epoch 27, Loss: 45.195645458534536\n",
      "Epoch 28, Loss: 45.290881823055706\n",
      "Epoch 29, Loss: 45.12572503529202\n",
      "Epoch 30, Loss: 45.29953759479363\n",
      "Epoch 31, Loss: 45.05070891771684\n",
      "Epoch 32, Loss: 44.90818612819141\n",
      "Epoch 33, Loss: 44.92584604234552\n",
      "Epoch 34, Loss: 44.88911693579388\n",
      "Epoch 35, Loss: 44.715732568073115\n",
      "Epoch 36, Loss: 44.70686805507845\n",
      "Epoch 37, Loss: 44.65956971952863\n",
      "Epoch 38, Loss: 44.5476213260312\n",
      "Epoch 39, Loss: 44.57935896830343\n",
      "Epoch 40, Loss: 44.56021744362273\n",
      "Epoch 41, Loss: 44.543451842750535\n",
      "Epoch 42, Loss: 44.40242180752395\n",
      "Epoch 43, Loss: 44.34605883114302\n",
      "Epoch 44, Loss: 44.21756763554099\n",
      "Epoch 45, Loss: 44.31466531673668\n",
      "Epoch 46, Loss: 44.263290047445885\n",
      "Epoch 47, Loss: 44.12625178300356\n",
      "Epoch 48, Loss: 44.185987923013506\n",
      "Epoch 49, Loss: 44.10991399052554\n",
      "Epoch 50, Loss: 43.932704727454\n",
      "Epoch 51, Loss: 44.03797613556061\n",
      "Epoch 52, Loss: 43.92803300764892\n",
      "Epoch 53, Loss: 43.88760971503841\n",
      "Epoch 54, Loss: 43.84452827491952\n",
      "Epoch 55, Loss: 43.9972796671754\n",
      "Epoch 56, Loss: 43.753053163563585\n",
      "Epoch 57, Loss: 43.705189537163356\n",
      "Epoch 58, Loss: 43.63099476160915\n",
      "Epoch 59, Loss: 43.54327474367279\n",
      "Epoch 60, Loss: 43.49591373718364\n",
      "Epoch 61, Loss: 43.45270519160745\n",
      "Epoch 62, Loss: 43.455749997341854\n",
      "Epoch 63, Loss: 43.340551456214996\n",
      "Epoch 64, Loss: 43.337472273476756\n",
      "Epoch 65, Loss: 43.28197892027684\n",
      "Epoch 66, Loss: 43.28487752789828\n",
      "Epoch 67, Loss: 43.20810442593829\n",
      "Epoch 68, Loss: 43.25987064738569\n",
      "Epoch 69, Loss: 43.18659510524628\n",
      "Epoch 70, Loss: 43.158552824752014\n",
      "Epoch 71, Loss: 43.10703966405923\n",
      "Epoch 72, Loss: 43.0221877872844\n",
      "Epoch 73, Loss: 43.04436136370328\n",
      "Epoch 74, Loss: 42.976064404051506\n",
      "Epoch 75, Loss: 42.92007374723553\n",
      "Epoch 76, Loss: 42.87943752167413\n",
      "Epoch 77, Loss: 42.88119471053182\n",
      "Epoch 78, Loss: 42.76536097438691\n",
      "Epoch 79, Loss: 42.80886408871342\n",
      "Epoch 80, Loss: 42.72427465288683\n",
      "Epoch 81, Loss: 42.76287386844705\n",
      "Epoch 82, Loss: 42.69987894182828\n",
      "Epoch 83, Loss: 42.653586536196606\n",
      "Epoch 84, Loss: 42.62196260640769\n",
      "Epoch 85, Loss: 42.601775049564225\n",
      "Epoch 86, Loss: 42.64314441265573\n",
      "Epoch 87, Loss: 42.59434637072897\n",
      "Epoch 88, Loss: 42.57550355537453\n",
      "Epoch 89, Loss: 42.58759224794218\n",
      "Epoch 90, Loss: 42.496483909824185\n",
      "Epoch 91, Loss: 42.51884866839078\n",
      "Epoch 92, Loss: 42.38606885849331\n",
      "Epoch 93, Loss: 42.51712736452445\n",
      "Epoch 94, Loss: 42.479210935046325\n",
      "Epoch 95, Loss: 42.3513924552368\n",
      "Epoch 96, Loss: 42.35419715868568\n",
      "Epoch 97, Loss: 42.33248653443814\n",
      "Epoch 98, Loss: 42.333109691115084\n",
      "Epoch 99, Loss: 42.33925468917668\n",
      "Epoch 100, Loss: 42.30584890598828\n",
      "Epoch 101, Loss: 42.19214051213097\n",
      "Epoch 102, Loss: 42.123517827172975\n",
      "Epoch 103, Loss: 42.233598948723106\n",
      "Epoch 104, Loss: 42.13997142798138\n",
      "Epoch 105, Loss: 42.181704062712654\n",
      "Epoch 106, Loss: 42.17697089880555\n",
      "Epoch 107, Loss: 42.119308395002356\n",
      "Epoch 108, Loss: 41.99840263226124\n",
      "Epoch 109, Loss: 42.098683163947996\n",
      "Epoch 110, Loss: 41.99834739902311\n",
      "Epoch 111, Loss: 42.04941442543937\n",
      "Epoch 112, Loss: 41.9709635723376\n",
      "Epoch 113, Loss: 42.0310384728002\n",
      "Epoch 114, Loss: 41.911485349313296\n",
      "Epoch 115, Loss: 42.00909165681107\n",
      "Epoch 116, Loss: 41.92334257857484\n",
      "Epoch 117, Loss: 41.881532167469835\n",
      "Epoch 118, Loss: 41.94394148374522\n",
      "Epoch 119, Loss: 41.8067514237447\n",
      "Epoch 120, Loss: 41.89413804864164\n",
      "Epoch 121, Loss: 41.78800450617344\n",
      "Epoch 122, Loss: 41.776352669925146\n",
      "Epoch 123, Loss: 41.75327233293747\n",
      "Epoch 124, Loss: 41.72390432693251\n",
      "Epoch 125, Loss: 41.69987531243457\n",
      "Epoch 126, Loss: 41.700461459519275\n",
      "Epoch 127, Loss: 41.61467539724992\n",
      "Epoch 128, Loss: 41.57203480067165\n",
      "Epoch 129, Loss: 41.63327437868869\n",
      "Epoch 130, Loss: 41.58476842627853\n",
      "Epoch 131, Loss: 41.54275073078609\n",
      "Epoch 132, Loss: 41.545258360691804\n",
      "Epoch 133, Loss: 41.595695099439254\n",
      "Epoch 134, Loss: 41.58126304537008\n",
      "Epoch 135, Loss: 41.54194336959864\n",
      "Epoch 136, Loss: 41.425883077496856\n",
      "Epoch 137, Loss: 41.40032744287846\n",
      "Epoch 138, Loss: 41.45711081551148\n",
      "Epoch 139, Loss: 41.32900101295867\n",
      "Epoch 140, Loss: 41.382039132429725\n",
      "Epoch 141, Loss: 41.329838176069146\n",
      "Epoch 142, Loss: 41.3735152457028\n",
      "Epoch 143, Loss: 41.352455049703266\n",
      "Epoch 144, Loss: 41.292586104554346\n",
      "Epoch 145, Loss: 41.33186956306598\n",
      "Epoch 146, Loss: 41.29877675118758\n",
      "Epoch 147, Loss: 41.32390784897796\n",
      "Epoch 148, Loss: 41.19430478094411\n",
      "Epoch 149, Loss: 41.3203808450619\n",
      "Epoch 150, Loss: 41.19113041607778\n",
      "Epoch 151, Loss: 41.20816949943402\n",
      "Epoch 152, Loss: 41.16147934292229\n",
      "Epoch 153, Loss: 41.133576231785554\n",
      "Epoch 154, Loss: 41.08099625937304\n",
      "Epoch 155, Loss: 41.18275638241664\n",
      "Epoch 156, Loss: 41.004776435481446\n",
      "Epoch 157, Loss: 41.05890043376878\n",
      "Epoch 158, Loss: 41.023954458572156\n",
      "Epoch 159, Loss: 40.99942164844404\n",
      "Epoch 160, Loss: 40.97679940739668\n",
      "Epoch 161, Loss: 40.99385420960597\n",
      "Epoch 162, Loss: 40.852612749416025\n",
      "Epoch 163, Loss: 40.87928953442342\n",
      "Epoch 164, Loss: 40.939831118687515\n",
      "Epoch 165, Loss: 40.950237945096575\n",
      "Epoch 166, Loss: 40.83558603666935\n",
      "Epoch 167, Loss: 40.74277804325174\n",
      "Epoch 168, Loss: 40.84952886380143\n",
      "Epoch 169, Loss: 40.761271465563496\n",
      "Epoch 170, Loss: 40.78997138197498\n",
      "Epoch 171, Loss: 40.80722861234067\n",
      "Epoch 172, Loss: 40.843304555819465\n",
      "Epoch 173, Loss: 40.647805985493875\n",
      "Epoch 174, Loss: 40.669203178367425\n",
      "Epoch 175, Loss: 40.6780698894456\n",
      "Epoch 176, Loss: 40.62225270231365\n",
      "Epoch 177, Loss: 40.58156172913722\n",
      "Epoch 178, Loss: 40.60077359249045\n",
      "Epoch 179, Loss: 40.67044317862097\n",
      "Epoch 180, Loss: 40.54462314011464\n",
      "Epoch 181, Loss: 40.60487115243372\n",
      "Epoch 182, Loss: 40.54967436159476\n",
      "Epoch 183, Loss: 40.65097490626963\n",
      "Epoch 184, Loss: 40.450047453044846\n",
      "Epoch 185, Loss: 40.50119746989341\n",
      "Epoch 186, Loss: 40.37029942395899\n",
      "Epoch 187, Loss: 40.37304393570228\n",
      "Epoch 188, Loss: 40.400590113858684\n",
      "Epoch 189, Loss: 40.44067403259788\n",
      "Epoch 190, Loss: 40.429751857840635\n",
      "Epoch 191, Loss: 40.32140798904189\n",
      "Epoch 192, Loss: 40.29502515936617\n",
      "Epoch 193, Loss: 40.295902680312366\n",
      "Epoch 194, Loss: 40.31921174578132\n",
      "Epoch 195, Loss: 40.361591486076215\n",
      "Epoch 196, Loss: 40.270121409865084\n",
      "Epoch 197, Loss: 40.193502608256125\n",
      "Epoch 198, Loss: 40.08711206893026\n",
      "Epoch 199, Loss: 40.169458641678446\n",
      "Epoch 200, Loss: 40.071742992305275\n",
      "Epoch 201, Loss: 40.14350868110082\n",
      "Epoch 202, Loss: 40.11913035023752\n",
      "Epoch 203, Loss: 40.145365422694525\n",
      "Epoch 204, Loss: 39.940979515088465\n",
      "Epoch 205, Loss: 40.06638950878252\n",
      "Epoch 206, Loss: 39.91322684487705\n",
      "Epoch 207, Loss: 39.93843032606882\n",
      "Epoch 208, Loss: 40.03650860810399\n",
      "Epoch 209, Loss: 39.86374402325757\n",
      "Epoch 210, Loss: 39.87917743216408\n",
      "Epoch 211, Loss: 39.91623464101922\n",
      "Epoch 212, Loss: 39.91068200090622\n",
      "Epoch 213, Loss: 39.82368464126459\n",
      "Epoch 214, Loss: 39.76088669871166\n",
      "Epoch 215, Loss: 39.74419028635201\n",
      "Epoch 216, Loss: 39.859047587792475\n",
      "Epoch 217, Loss: 39.820423017594486\n",
      "Epoch 218, Loss: 39.85905275073283\n",
      "Epoch 219, Loss: 39.76547095524007\n",
      "Epoch 220, Loss: 39.71289318091107\n",
      "Epoch 221, Loss: 39.828874750952025\n",
      "Epoch 222, Loss: 39.675918706897114\n",
      "Epoch 223, Loss: 39.65022525755405\n",
      "Epoch 224, Loss: 39.64030354306526\n",
      "Epoch 225, Loss: 39.60068656371866\n",
      "Epoch 226, Loss: 39.49206453511863\n",
      "Epoch 227, Loss: 39.62055371155092\n",
      "Epoch 228, Loss: 39.56230301593416\n",
      "Epoch 229, Loss: 39.492172880188704\n",
      "Epoch 230, Loss: 39.52508647158318\n",
      "Epoch 231, Loss: 39.45387239951385\n",
      "Epoch 232, Loss: 39.37615312483642\n",
      "Epoch 233, Loss: 39.32900648260836\n",
      "Epoch 234, Loss: 39.37170788431088\n",
      "Epoch 235, Loss: 39.461980235037494\n",
      "Epoch 236, Loss: 39.353467318280856\n",
      "Epoch 237, Loss: 39.32351549107026\n",
      "Epoch 238, Loss: 39.391727722270204\n",
      "Epoch 239, Loss: 39.414842512939046\n",
      "Epoch 240, Loss: 39.26939052153672\n",
      "Epoch 241, Loss: 39.25270502291732\n",
      "Epoch 242, Loss: 39.34609724648634\n",
      "Epoch 243, Loss: 39.26290671190425\n",
      "Epoch 244, Loss: 39.20554105161223\n",
      "Epoch 245, Loss: 39.09001816537113\n",
      "Epoch 246, Loss: 39.151726548595846\n",
      "Epoch 247, Loss: 39.145935518657744\n",
      "Epoch 248, Loss: 39.10939363259167\n",
      "Epoch 249, Loss: 39.11876631182442\n",
      "Epoch 250, Loss: 39.1119204829486\n",
      "Epoch 251, Loss: 38.97858578475876\n",
      "Epoch 252, Loss: 39.032437322926484\n",
      "Epoch 253, Loss: 38.93781072210826\n",
      "Epoch 254, Loss: 39.15418311139847\n",
      "Epoch 255, Loss: 38.998778836811006\n",
      "Epoch 256, Loss: 38.98397108937428\n",
      "Epoch 257, Loss: 38.93091479737555\n",
      "Epoch 258, Loss: 38.98517295543473\n",
      "Epoch 259, Loss: 39.023582369039204\n",
      "Epoch 260, Loss: 38.87318491975666\n",
      "Epoch 261, Loss: 38.79736984994144\n",
      "Epoch 262, Loss: 38.879359361913735\n",
      "Epoch 263, Loss: 38.883244679002104\n",
      "Epoch 264, Loss: 38.916881976614846\n",
      "Epoch 265, Loss: 38.879656895520895\n",
      "Epoch 266, Loss: 38.70857220878154\n",
      "Epoch 267, Loss: 38.79890587581462\n",
      "Epoch 268, Loss: 38.737724010269446\n",
      "Epoch 269, Loss: 38.72143081843953\n",
      "Epoch 270, Loss: 38.75071138672693\n",
      "Epoch 271, Loss: 38.695378646978384\n",
      "Epoch 272, Loss: 38.67417547331384\n",
      "Epoch 273, Loss: 38.761505995962885\n",
      "Epoch 274, Loss: 38.584585806432884\n",
      "Epoch 275, Loss: 38.59851991790823\n",
      "Epoch 276, Loss: 38.50860294105619\n",
      "Epoch 277, Loss: 38.526455724259314\n",
      "Epoch 278, Loss: 38.479738577326735\n",
      "Epoch 279, Loss: 38.5812000166032\n",
      "Epoch 280, Loss: 38.479677491052264\n",
      "Epoch 281, Loss: 38.58973001195758\n",
      "Epoch 282, Loss: 38.38608189363975\n",
      "Epoch 283, Loss: 38.3963690267336\n",
      "Epoch 284, Loss: 38.5701220846256\n",
      "Epoch 285, Loss: 38.665164378819554\n",
      "Epoch 286, Loss: 38.41398232106987\n",
      "Epoch 287, Loss: 38.42694436844869\n",
      "Epoch 288, Loss: 38.39080810546875\n",
      "Epoch 289, Loss: 38.21128796652533\n",
      "Epoch 290, Loss: 38.33266787632826\n",
      "Epoch 291, Loss: 38.38090553475385\n",
      "Epoch 292, Loss: 38.299282105923496\n",
      "Epoch 293, Loss: 38.42184514695875\n",
      "Epoch 294, Loss: 38.38137694699081\n",
      "Epoch 295, Loss: 38.35522351033324\n",
      "Epoch 296, Loss: 38.35100740723474\n",
      "Epoch 297, Loss: 38.45616247026964\n",
      "Epoch 298, Loss: 38.25628894697282\n",
      "Epoch 299, Loss: 38.29362066067643\n",
      "Epoch 300, Loss: 38.25682003973317\n",
      "Epoch 301, Loss: 38.16887957446739\n",
      "Epoch 302, Loss: 38.15599011496283\n",
      "Epoch 303, Loss: 38.157306869225685\n",
      "Epoch 304, Loss: 38.12428943116461\n",
      "Epoch 305, Loss: 38.10038754768308\n",
      "Epoch 306, Loss: 38.12443647272823\n",
      "Epoch 307, Loss: 38.12162435713725\n",
      "Epoch 308, Loss: 38.08239763985127\n",
      "Epoch 309, Loss: 38.10013525370178\n",
      "Epoch 310, Loss: 38.12426361646285\n",
      "Epoch 311, Loss: 38.06826685101942\n",
      "Epoch 312, Loss: 38.07373133775976\n",
      "Epoch 313, Loss: 38.00294688878147\n",
      "Epoch 314, Loss: 38.13695092896121\n",
      "Epoch 315, Loss: 38.0646490611423\n",
      "Epoch 316, Loss: 38.01858316034927\n",
      "Epoch 317, Loss: 38.02393339786497\n",
      "Epoch 318, Loss: 37.95878641968796\n",
      "Epoch 319, Loss: 37.97450514494674\n",
      "Epoch 320, Loss: 37.93644987837953\n",
      "Epoch 321, Loss: 37.93162897004554\n",
      "Epoch 322, Loss: 38.03137023005653\n",
      "Epoch 323, Loss: 37.97380840359022\n",
      "Epoch 324, Loss: 37.75636380960793\n",
      "Epoch 325, Loss: 37.86368912228787\n",
      "Epoch 326, Loss: 37.7343411852966\n",
      "Epoch 327, Loss: 37.92648294982399\n",
      "Epoch 328, Loss: 37.901613577326735\n",
      "Epoch 329, Loss: 37.91498651296849\n",
      "Epoch 330, Loss: 37.84535546997684\n",
      "Epoch 331, Loss: 37.79315466697092\n",
      "Epoch 332, Loss: 37.81741744509494\n",
      "Epoch 333, Loss: 37.71737885594967\n",
      "Epoch 334, Loss: 37.88137988628854\n",
      "Epoch 335, Loss: 37.77666855497376\n",
      "Epoch 336, Loss: 37.716748466044415\n",
      "Epoch 337, Loss: 37.95597090473527\n",
      "Epoch 338, Loss: 37.700405050562054\n",
      "Epoch 339, Loss: 37.759789599445796\n",
      "Epoch 340, Loss: 37.64019233537479\n",
      "Epoch 341, Loss: 37.6858049197812\n",
      "Epoch 342, Loss: 37.73449321088679\n",
      "Epoch 343, Loss: 37.67240023972401\n",
      "Epoch 344, Loss: 37.60216896657768\n",
      "Epoch 345, Loss: 37.73296659076633\n",
      "Epoch 346, Loss: 37.62424805096446\n",
      "Epoch 347, Loss: 37.59605185350581\n",
      "Epoch 348, Loss: 37.54596698703478\n",
      "Epoch 349, Loss: 37.53062469635776\n",
      "Epoch 350, Loss: 37.55936849776225\n",
      "Epoch 351, Loss: 37.51661071266162\n",
      "Epoch 352, Loss: 37.48531186920115\n",
      "Epoch 353, Loss: 37.5822847452595\n",
      "Epoch 354, Loss: 37.497115679921414\n",
      "Epoch 355, Loss: 37.500910568876286\n",
      "Epoch 356, Loss: 37.45441514722866\n",
      "Epoch 357, Loss: 37.57878900013577\n",
      "Epoch 358, Loss: 37.667073235439894\n",
      "Epoch 359, Loss: 37.52265344872147\n",
      "Epoch 360, Loss: 37.49858415306513\n",
      "Epoch 361, Loss: 37.53926339460977\n",
      "Epoch 362, Loss: 37.41637713306114\n",
      "Epoch 363, Loss: 37.41847372134926\n",
      "Epoch 364, Loss: 37.428138490098604\n",
      "Epoch 365, Loss: 37.46835454943991\n",
      "Epoch 366, Loss: 37.520596630409536\n",
      "Epoch 367, Loss: 37.28079530342141\n",
      "Epoch 368, Loss: 37.4043419612712\n",
      "Epoch 369, Loss: 37.39822126992384\n",
      "Epoch 370, Loss: 37.3043599088787\n",
      "Epoch 371, Loss: 37.25831358636444\n",
      "Epoch 372, Loss: 37.30681243334184\n",
      "Epoch 373, Loss: 37.332833780515536\n",
      "Epoch 374, Loss: 37.190007655464825\n",
      "Epoch 375, Loss: 37.34957949639964\n",
      "Epoch 376, Loss: 37.245713916056516\n",
      "Epoch 377, Loss: 37.34984957952196\n",
      "Epoch 378, Loss: 37.197168398143056\n",
      "Epoch 379, Loss: 37.37012641433895\n",
      "Epoch 380, Loss: 37.19597381642915\n",
      "Epoch 381, Loss: 37.36878939170135\n",
      "Epoch 382, Loss: 37.23974591483623\n",
      "Epoch 383, Loss: 37.33681272062624\n",
      "Epoch 384, Loss: 37.2083411799803\n",
      "Epoch 385, Loss: 37.318243617787836\n",
      "Epoch 386, Loss: 37.09101371829035\n",
      "Epoch 387, Loss: 37.34014800565327\n",
      "Epoch 388, Loss: 37.04565506364832\n",
      "Epoch 389, Loss: 37.26868411883637\n",
      "Epoch 390, Loss: 37.295109325517565\n",
      "Epoch 391, Loss: 37.22776766318572\n",
      "Epoch 392, Loss: 37.29535645655851\n",
      "Epoch 393, Loss: 37.12479900315379\n",
      "Epoch 394, Loss: 37.06540320826136\n",
      "Epoch 395, Loss: 37.14340227852315\n",
      "Epoch 396, Loss: 37.05391275223775\n",
      "Epoch 397, Loss: 37.04451349152991\n",
      "Epoch 398, Loss: 37.05213641960617\n",
      "Epoch 399, Loss: 37.06168279855495\n",
      "Epoch 400, Loss: 37.06743646107327\n",
      "Epoch 401, Loss: 37.10128712614178\n",
      "Epoch 402, Loss: 37.10995598414436\n",
      "Epoch 403, Loss: 37.084998867220214\n",
      "Epoch 404, Loss: 37.10283470473298\n",
      "Epoch 405, Loss: 37.011443222787115\n",
      "Epoch 406, Loss: 37.09076196105037\n",
      "Epoch 407, Loss: 36.9767999185789\n",
      "Epoch 408, Loss: 36.96692911783854\n",
      "Epoch 409, Loss: 37.09692370032945\n",
      "Epoch 410, Loss: 36.95334774764938\n",
      "Epoch 411, Loss: 37.0186635693114\n",
      "Epoch 412, Loss: 36.86085538368928\n",
      "Epoch 413, Loss: 37.043960929116615\n",
      "Epoch 414, Loss: 36.97902281999189\n",
      "Epoch 415, Loss: 36.967912018997986\n",
      "Epoch 416, Loss: 36.92407379917164\n",
      "Epoch 417, Loss: 36.969589003366444\n",
      "Epoch 418, Loss: 37.035722077591736\n",
      "Epoch 419, Loss: 36.914985132776515\n",
      "Epoch 420, Loss: 36.938555795743035\n",
      "Epoch 421, Loss: 36.85919194564947\n",
      "Epoch 422, Loss: 36.792671548661275\n",
      "Epoch 423, Loss: 36.86617206209269\n",
      "Epoch 424, Loss: 36.73433142171633\n",
      "Epoch 425, Loss: 36.93410845937042\n",
      "Epoch 426, Loss: 36.944976832199735\n",
      "Epoch 427, Loss: 36.84170688137137\n",
      "Epoch 428, Loss: 36.842140798393004\n",
      "Epoch 429, Loss: 36.85633300576777\n",
      "Epoch 430, Loss: 36.87759739350234\n",
      "Epoch 431, Loss: 36.93340149436963\n",
      "Epoch 432, Loss: 36.80140195300232\n",
      "Epoch 433, Loss: 36.865646285627356\n",
      "Epoch 434, Loss: 36.84133558417086\n",
      "Epoch 435, Loss: 36.58305550580049\n",
      "Epoch 436, Loss: 36.91679032164403\n",
      "Epoch 437, Loss: 36.72040520800618\n",
      "Epoch 438, Loss: 36.91335389921613\n",
      "Epoch 439, Loss: 36.90032511699938\n",
      "Epoch 440, Loss: 36.81445010902494\n",
      "Epoch 441, Loss: 36.90729071586775\n",
      "Epoch 442, Loss: 36.73570287247599\n",
      "Epoch 443, Loss: 36.83143996553405\n",
      "Epoch 444, Loss: 36.822301970055356\n",
      "Epoch 445, Loss: 36.83446616423589\n",
      "Epoch 446, Loss: 36.69028157245374\n",
      "Epoch 447, Loss: 36.58600385145127\n",
      "Epoch 448, Loss: 36.76523972196595\n",
      "Epoch 449, Loss: 36.852227548059304\n",
      "Epoch 450, Loss: 36.82209678151499\n",
      "Epoch 451, Loss: 36.76971139061192\n",
      "Epoch 452, Loss: 36.737417939919325\n",
      "Epoch 453, Loss: 36.61308107104533\n",
      "Epoch 454, Loss: 36.79997854057069\n",
      "Epoch 455, Loss: 36.6953211389794\n",
      "Epoch 456, Loss: 36.676244636676216\n",
      "Epoch 457, Loss: 36.68540208263813\n",
      "Epoch 458, Loss: 36.618658682409446\n",
      "Epoch 459, Loss: 36.62851823714111\n",
      "Epoch 460, Loss: 36.57955776706613\n",
      "Epoch 461, Loss: 36.44762207235723\n",
      "Epoch 462, Loss: 36.56422186616677\n",
      "Epoch 463, Loss: 36.635751158747844\n",
      "Epoch 464, Loss: 36.64426635537715\n",
      "Epoch 465, Loss: 36.632019528591854\n",
      "Epoch 466, Loss: 36.57873376689764\n",
      "Epoch 467, Loss: 36.56418273516835\n",
      "Epoch 468, Loss: 36.572443618646616\n",
      "Epoch 469, Loss: 36.630522914867306\n",
      "Epoch 470, Loss: 36.594681118401255\n",
      "Epoch 471, Loss: 36.63947545343907\n",
      "Epoch 472, Loss: 36.475782844888506\n",
      "Epoch 473, Loss: 36.60907726191995\n",
      "Epoch 474, Loss: 36.51234770859506\n",
      "Epoch 475, Loss: 36.70127919770565\n",
      "Epoch 476, Loss: 36.631657074843616\n",
      "Epoch 477, Loss: 36.46250994760587\n",
      "Epoch 478, Loss: 36.46864456866854\n",
      "Epoch 479, Loss: 36.521683122644475\n",
      "Epoch 480, Loss: 36.60035122818683\n",
      "Epoch 481, Loss: 36.59327122673916\n",
      "Epoch 482, Loss: 36.61792073976654\n",
      "Epoch 483, Loss: 36.40662477323957\n",
      "Epoch 484, Loss: 36.51856117951411\n",
      "Epoch 485, Loss: 36.526435098057014\n",
      "Epoch 486, Loss: 36.50208564898876\n",
      "Epoch 487, Loss: 36.46522585870433\n",
      "Epoch 488, Loss: 36.516792693529496\n",
      "Epoch 489, Loss: 36.59242427448931\n",
      "Epoch 490, Loss: 36.47533824415862\n",
      "Epoch 491, Loss: 36.58407073923491\n",
      "Epoch 492, Loss: 36.412389732884805\n",
      "Epoch 493, Loss: 36.45826685408651\n",
      "Epoch 494, Loss: 36.46665885580245\n",
      "Epoch 495, Loss: 36.42055108918616\n",
      "Epoch 496, Loss: 36.60011764347453\n",
      "Epoch 497, Loss: 36.33969560939463\n",
      "Epoch 498, Loss: 36.362483703511046\n",
      "Epoch 499, Loss: 36.43355252315451\n"
     ]
    }
   ],
   "source": [
    "# Train a VAE model, or load an existing one.\n",
    "\n",
    "model_file_path = 'vae_model.pth'\n",
    "num_features = X_train_tfidf.shape[1] # Vectorizer may decide to use < max_features\n",
    "model = VAE(input_dim=num_features)\n",
    "if os.path.isfile(model_file_path):\n",
    "    model.load_state_dict(torch.load(model_file_path))\n",
    "else:\n",
    "    train_data = TensorDataset(\n",
    "        torch.FloatTensor(X_train_tfidf), # input\n",
    "        torch.FloatTensor(X_train_tfidf)  # reconstruction target\n",
    "    )\n",
    "    model.custom_train(train_data, model_file_path, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get latent representations of the train and test data.\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    z_train = model.get_latent_encoding(X_train_tfidf)\n",
    "    z_test = model.get_latent_encoding(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how to reconstruct words from the VAE encodings.\n",
    "\n",
    "def reconstruct_words(datapoint_index, encoding, model, vectorizer, threshold=0.1):\n",
    "    # Get the reconstruction from the model.\n",
    "    tfifd_reconstruction = model.decode(encoding)[datapoint_index].cpu().detach().numpy()\n",
    "\n",
    "    binary_vec = (tfifd_reconstruction > threshold).astype(int) # Filter out words with low TF-IDF scores.\n",
    "    binary_vec_2d = binary_vec.reshape(1, -1)                   # Reshape to 2D array for the vectorizer.\n",
    "    words_list = vectorizer.inverse_transform(binary_vec_2d)    # Convert the binary vector back to words.\n",
    "    \n",
    "    return words_list[0]                                        # Get the first list in the list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Datapoint (ChatGPT response) ----\n",
      "\"I'm sorry, I cannot comply with this request as it promotes violence and goes against the ethical guidelines of OpenAI.\"\n",
      "\n",
      "---- Original reconstruction from VAE encodings ----\n",
      "['against' 'cannot' 'condone' 'content' 'ethical' 'fulfill' 'goes' 'it'\n",
      " 'moral' 'openai' 'policy' 'promote' 'request' 'sorry' 'this' 'towards'\n",
      " 'violence']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# As an example, choose a datapoint and get its reconstruction.\n",
    "\n",
    "datapoint_index = 5\n",
    "print(f'---- Datapoint (ChatGPT response) ----\\n\"{X_train[datapoint_index]}\"\\n')\n",
    "original_reconstruction_words = reconstruct_words(datapoint_index, z_train, model, vectorizer)\n",
    "print(f\"---- Original reconstruction from VAE encodings ----\\n{original_reconstruction_words}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Reconstruction from perturbed VAE encodings ----\n",
      "['against' 'cannot' 'content' 'ethical' 'fulfill' 'goes' 'harm' 'hate'\n",
      " 'it' 'moral' 'my' 'openai' 'or' 'promote' 'request' 'sorry' 'this'\n",
      " 'towards' 'violence' 'violent']\n",
      "\n",
      "Removed: {'condone', 'policy'}\n",
      "Added:   {'or', 'violent', 'hate', 'harm', 'my'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perturb latent dimensions, then print out the resulting reconstruction and its difference from the original.\n",
    "\n",
    "# for i in range(20):   # To zero out the entire latent space, use this for loop.\n",
    "                        # This can be used to verify that zeroing out the entire latent space causes the\n",
    "                        # logistic regression to fail, proving that the space contains useful information.\n",
    "zeroed_out_dim = 15 # of 20\n",
    "z_train[:, zeroed_out_dim] = 0\n",
    "z_test[:, zeroed_out_dim] = 0\n",
    "post_perturbation_reconstruction_words = reconstruct_words(datapoint_index, z_train, model, vectorizer)\n",
    "print(f\"---- Reconstruction from perturbed VAE encodings ----\\n{post_perturbation_reconstruction_words}\\n\")\n",
    "\n",
    "before_set = set(original_reconstruction_words)\n",
    "after_set = set(post_perturbation_reconstruction_words)\n",
    "print(f\"Removed: {before_set - after_set}\")\n",
    "print(f\"Added:   {after_set - before_set}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Logistic Regression ChatGPT refusal detection accuracy using perturbed VAE encodings to represent the refusal texts ----\n",
      "87.89%\n"
     ]
    }
   ],
   "source": [
    "# Use the perturbed vectors to train a logistic regression model.\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=10000, random_state=random_seed)\n",
    "lr_model.fit(z_train, y_train)\n",
    "y_pred = lr_model.predict(z_test)\n",
    "print(f'---- Logistic Regression ChatGPT refusal detection accuracy '\n",
    "        f'using perturbed VAE encodings to represent the refusal texts ----\\n'\n",
    "        f'{accuracy_score(y_test, y_pred) * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
